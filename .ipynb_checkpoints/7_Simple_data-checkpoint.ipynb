{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#my stuff\n",
    "import icu_data_defs\n",
    "import transformers\n",
    "import utils\n",
    "import features\n",
    "from constants import column_names,variable_type,clinical_source\n",
    "import units\n",
    "import mimic\n",
    "import logger\n",
    "\n",
    "#other stuff\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,ShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression,ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#make pretty pictures\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HELPER FUNCTIONS\n",
    "\n",
    "def run_crossval(pipeline,X,y):\n",
    "    scores_r2 = cross_val_score(pipeline,X,y, scoring='r2',cv=10)\n",
    "    scores_nmse = cross_val_score(pipeline,X,y, scoring='neg_mean_squared_error',cv=10)\n",
    "\n",
    "    print 'Cross Validation, K-Fold'\n",
    "    print 'R^2: {}, {}'.format(scores_r2.mean(),scores_r2.std())\n",
    "    print 'RMSE: {}, {}'.format(np.sqrt(-1.0*scores_nmse).mean(),np.sqrt(-1.0*scores_nmse).std())\n",
    "\n",
    "    cv_shuffle = ShuffleSplit(n_splits=10,test_size=0.1)\n",
    "\n",
    "    scores_r2 = cross_val_score(pipeline,X,y, scoring='r2',cv=cv_shuffle)\n",
    "    scores_nmse = cross_val_score(pipeline,X,y, scoring='neg_mean_squared_error', cv=cv_shuffle)\n",
    "\n",
    "    print '\\nCross Validation, ShuffleSplit'\n",
    "    print 'R^2: {}, {}'.format(scores_r2.mean(),scores_r2.std())\n",
    "    print 'RMSE: {}, {}'.format(np.sqrt(-1.0*scores_nmse).mean(),np.sqrt(-1.0*scores_nmse).std())\n",
    "    return\n",
    "\n",
    "\"\"\"\n",
    "Getting lactate labels (next and delta)\n",
    "\"\"\"\n",
    "def get_labels_next_lac(lactate_series):\n",
    "    return lactate_series.shift(-1).dropna().iloc[:,0]\n",
    "\n",
    "def get_labels_delta_lac(lactate_series):\n",
    "    id_grouped = lactate_series.groupby(level='id')\n",
    "    lac_filled = id_grouped.ffill()\n",
    "    lac_next = id_grouped.shift(-1)\n",
    "    lac_all = lac_filled\n",
    "    lac_all.columns = ['last']\n",
    "    lac_all['next'] = lac_next\n",
    "    lac_all = lac_all.dropna()\n",
    "    return lac_all['next'] - lac_all['last']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Visualize data\n",
    "\"\"\"\n",
    "#Visualize\n",
    "def viz_per_feature(df_features,label_dict):  \n",
    "    plot_cnt = len(label_dict)+1\n",
    "    \n",
    "    df_corr = pd.DataFrame(index=df_features.columns,columns=label_dict.keys())\n",
    "    \n",
    "    for col_name in df_features:\n",
    "        print col_name\n",
    "        col = df_features[col_name]\n",
    "        display(col.describe().apply(lambda x: '%.4f' % x).to_frame())\n",
    "        #determine # of filled values\n",
    "        mode = col.mode()\n",
    "        print mode\n",
    "        mode_count = (col == mode).sum()\n",
    "        print \"MODE:\",mode\n",
    "        print mode_count\n",
    "        print mode_count/float(col.shape[0])\n",
    "\n",
    "\n",
    "        # plot histogram of column (all of df_train)\n",
    "        fig, axarr  = plt.subplots(1,plot_cnt,figsize=(5*(plot_cnt), 5))\n",
    "        ax = plt.subplot(1, plot_cnt, 1)\n",
    "        std = col.std()\n",
    "        mean = col.mean()\n",
    "        col.loc[(col < (mean + 3.0*std)) & (col > (mean - 3.0*std))].hist()\n",
    "        ax.set_title('{}_{}\\n{}'.format(col_name[0],col_name[1],col_name[2:]))\n",
    "        ax.set_xlabel(col[-2])\n",
    "        ax.set_ylabel('COUNT')\n",
    "\n",
    "        #plot this column vs. each label\n",
    "        for i,label_name in label_dict.keys():\n",
    "            y = label_dict[label_name]\n",
    "            \n",
    "            x = col.loc[y.index]\n",
    "            ax = plt.subplot(1, plot_cnt, 1+i)\n",
    "            sns.regplot(x, y)\n",
    "            corr = np.corrcoef(x, y)[0][1]\n",
    "            ax.set_title('{} \\n PCC (r) = {}'.format(label_name,corr))\n",
    "            df_corr.loc[col_name,label_name]=corr\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return df_corr\n",
    "        \n",
    "\"\"\"\n",
    "Test/train/validate split\n",
    "\"\"\"\n",
    "\n",
    "def test_train_val_split(all_ids=None,test_size=0.1,random_state=42,print_ids=False):\n",
    "\n",
    "    if all_ids is None:\n",
    "        all_ids = mimic.get_all_hadm_ids()\n",
    "    \n",
    "    validate_size = test_size/(1-test_size)\n",
    "    train_size = (1-test_size)*(1-validate_size)\n",
    "    #these test IDs will never be touched again. They are sacred\n",
    "    train_val_ids,test_ids = train_test_split(all_ids,test_size=test_size,random_state=random_state)\n",
    "    train_ids,validate_ids = train_test_split(train_val_ids,test_size=validate_size,random_state=random_state)\n",
    "\n",
    "    if print_ids:\n",
    "        print 'Train {}:'.format(int(train_size*100)), len(train_ids),'>',train_ids[:5],'...'\n",
    "        print 'Validate {}:'.format(int(train_size*100)), len(validate_ids),'>',validate_ids[:5],'...'\n",
    "        print 'Test {}:'.format(int(test_size*100)), len(test_ids),'>',test_ids[:5],'...'\n",
    "    return train_ids,validate_ids,test_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 80: 47180 > [139698, 127590, 178959, 139276, 196600] ...\n",
      "Validate 80: 5898 > [112338, 107467, 158733, 144544, 115417] ...\n",
      "Test 10: 5898 > [167957, 164747, 124147, 184424, 136508] ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component</th>\n",
       "      <th>units</th>\n",
       "      <th>variable_type</th>\n",
       "      <th>clinical_source</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>list_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heart rate</td>\n",
       "      <td>beats/min</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blood pressure systolic</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blood pressure diastolic</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blood pressure mean</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>respiratory rate</td>\n",
       "      <td>insp/min</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>temperature body</td>\n",
       "      <td>degF</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>oxygen saturation pulse oximetry</td>\n",
       "      <td>percent</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weight body</td>\n",
       "      <td>kg</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>output urine</td>\n",
       "      <td>mL</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>output urine</td>\n",
       "      <td>mL/hr</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>output urine</td>\n",
       "      <td>mL/kg/hr</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>glasgow coma scale motor</td>\n",
       "      <td>no_units</td>\n",
       "      <td>ord</td>\n",
       "      <td>observation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>glasgow coma scale eye opening</td>\n",
       "      <td>no_units</td>\n",
       "      <td>ord</td>\n",
       "      <td>observation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>glasgow coma scale verbal</td>\n",
       "      <td>no_units</td>\n",
       "      <td>ord</td>\n",
       "      <td>observation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>normal saline</td>\n",
       "      <td>mL</td>\n",
       "      <td>qn</td>\n",
       "      <td>intervention</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>normal saline</td>\n",
       "      <td>mL/hr</td>\n",
       "      <td>qn</td>\n",
       "      <td>intervention</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lactated ringers</td>\n",
       "      <td>mL</td>\n",
       "      <td>qn</td>\n",
       "      <td>intervention</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lactated ringers</td>\n",
       "      <td>mL/hr</td>\n",
       "      <td>qn</td>\n",
       "      <td>intervention</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>norepinephrine</td>\n",
       "      <td>mcg</td>\n",
       "      <td>qn</td>\n",
       "      <td>intervention</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>norepinephrine</td>\n",
       "      <td>mcg/min</td>\n",
       "      <td>qn</td>\n",
       "      <td>intervention</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>norepinephrine</td>\n",
       "      <td>mcg/kg/min</td>\n",
       "      <td>qn</td>\n",
       "      <td>intervention</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vasopressin</td>\n",
       "      <td>units</td>\n",
       "      <td>qn</td>\n",
       "      <td>intervention</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vasopressin</td>\n",
       "      <td>units/min</td>\n",
       "      <td>qn</td>\n",
       "      <td>intervention</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>lactate</td>\n",
       "      <td>mmol/L</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>lactate</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>hemoglobin</td>\n",
       "      <td>g/dL</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>white blood cell count</td>\n",
       "      <td>x10e3/uL</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>red blood cell count</td>\n",
       "      <td>x10e6/uL</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>hematocrit</td>\n",
       "      <td>percent</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>mean corpuscular volume</td>\n",
       "      <td>fL</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>glucose serum</td>\n",
       "      <td>mmol/L</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>glucose serum</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>glucose fingerstick</td>\n",
       "      <td>mmol/L</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>glucose fingerstick</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>calcium total serum</td>\n",
       "      <td>mmol/L</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>calcium total serum</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>calcium ionized serum</td>\n",
       "      <td>mmol/L</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>calcium ionized serum</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>magnesium serum</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>phosphorous serum</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>prothrombin time</td>\n",
       "      <td>seconds</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>partial thromboplastin time</td>\n",
       "      <td>seconds</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>international normalized ratio</td>\n",
       "      <td>no_units</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>partial pressure of oxygen arterial</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>partial pressure of carbon dioxide arterial</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>oxygen saturation arterial</td>\n",
       "      <td>percent</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>pH arterial</td>\n",
       "      <td>no_units</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>pH other</td>\n",
       "      <td>no_units</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>bicarbonate arterial</td>\n",
       "      <td>mEq/L</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>bicarbonate other</td>\n",
       "      <td>mEq/L</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>alanine aminotransferase serum</td>\n",
       "      <td>U/L</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>aspartate aminotransferase serum</td>\n",
       "      <td>U/L</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>alkaline phosphatase serum</td>\n",
       "      <td>IU/L</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>fraction of inspired oxygen</td>\n",
       "      <td>percent</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>fraction of inspired oxygen</td>\n",
       "      <td>no_units</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>positive end expiratory pressure</td>\n",
       "      <td>cmH2O</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>tidal volume</td>\n",
       "      <td>mL</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>central venous pressure</td>\n",
       "      <td>mm/Hg</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>central venous oxygen saturation</td>\n",
       "      <td>percent</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>end tidal cardon dioxide</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>qn</td>\n",
       "      <td>observation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          component       units variable_type  \\\n",
       "def_id                                                                          \n",
       "0                                        heart rate   beats/min            qn   \n",
       "1                           blood pressure systolic        mmHg            qn   \n",
       "2                          blood pressure diastolic        mmHg            qn   \n",
       "3                               blood pressure mean        mmHg            qn   \n",
       "4                                  respiratory rate    insp/min            qn   \n",
       "5                                  temperature body        degF            qn   \n",
       "6                  oxygen saturation pulse oximetry     percent            qn   \n",
       "7                                       weight body          kg            qn   \n",
       "8                                      output urine          mL            qn   \n",
       "9                                      output urine       mL/hr            qn   \n",
       "10                                     output urine    mL/kg/hr            qn   \n",
       "11                         glasgow coma scale motor    no_units           ord   \n",
       "12                   glasgow coma scale eye opening    no_units           ord   \n",
       "13                        glasgow coma scale verbal    no_units           ord   \n",
       "14                                    normal saline          mL            qn   \n",
       "15                                    normal saline       mL/hr            qn   \n",
       "16                                 lactated ringers          mL            qn   \n",
       "17                                 lactated ringers       mL/hr            qn   \n",
       "18                                   norepinephrine         mcg            qn   \n",
       "19                                   norepinephrine     mcg/min            qn   \n",
       "20                                   norepinephrine  mcg/kg/min            qn   \n",
       "21                                      vasopressin       units            qn   \n",
       "22                                      vasopressin   units/min            qn   \n",
       "23                                          lactate      mmol/L            qn   \n",
       "24                                          lactate       mg/dL            qn   \n",
       "25                                       hemoglobin        g/dL            qn   \n",
       "26                           white blood cell count    x10e3/uL            qn   \n",
       "27                             red blood cell count    x10e6/uL            qn   \n",
       "28                                       hematocrit     percent            qn   \n",
       "29                          mean corpuscular volume          fL            qn   \n",
       "...                                             ...         ...           ...   \n",
       "44                                    glucose serum      mmol/L            qn   \n",
       "45                                    glucose serum       mg/dL            qn   \n",
       "46                              glucose fingerstick      mmol/L            qn   \n",
       "47                              glucose fingerstick       mg/dL            qn   \n",
       "48                              calcium total serum      mmol/L            qn   \n",
       "49                              calcium total serum       mg/dL            qn   \n",
       "50                            calcium ionized serum      mmol/L            qn   \n",
       "51                            calcium ionized serum       mg/dL            qn   \n",
       "52                                  magnesium serum       mg/dL            qn   \n",
       "53                                phosphorous serum       mg/dL            qn   \n",
       "54                                 prothrombin time     seconds            qn   \n",
       "55                      partial thromboplastin time     seconds            qn   \n",
       "56                   international normalized ratio    no_units            qn   \n",
       "57              partial pressure of oxygen arterial        mmHg            qn   \n",
       "58      partial pressure of carbon dioxide arterial        mmHg            qn   \n",
       "59                       oxygen saturation arterial     percent            qn   \n",
       "60                                      pH arterial    no_units            qn   \n",
       "61                                         pH other    no_units            qn   \n",
       "62                             bicarbonate arterial       mEq/L            qn   \n",
       "63                                bicarbonate other       mEq/L            qn   \n",
       "64                   alanine aminotransferase serum         U/L            qn   \n",
       "65                 aspartate aminotransferase serum         U/L            qn   \n",
       "66                       alkaline phosphatase serum        IU/L            qn   \n",
       "67                      fraction of inspired oxygen     percent            qn   \n",
       "68                      fraction of inspired oxygen    no_units            qn   \n",
       "69                 positive end expiratory pressure       cmH2O            qn   \n",
       "70                                     tidal volume          mL            qn   \n",
       "71                          central venous pressure       mm/Hg            qn   \n",
       "72                 central venous oxygen saturation     percent            qn   \n",
       "73                         end tidal cardon dioxide        mmHg            qn   \n",
       "\n",
       "       clinical_source  lower     upper  list_id  \n",
       "def_id                                            \n",
       "0          observation    0.0     500.0      NaN  \n",
       "1          observation    0.0     500.0      NaN  \n",
       "2          observation    0.0     500.0      NaN  \n",
       "3          observation    0.0     500.0      NaN  \n",
       "4          observation    0.0     150.0      NaN  \n",
       "5          observation    0.0     150.0      NaN  \n",
       "6          observation    0.0     100.0      NaN  \n",
       "7          observation    0.0     700.0      NaN  \n",
       "8          observation    0.0   30000.0      NaN  \n",
       "9          observation    0.0    5000.0      NaN  \n",
       "10         observation    0.0     100.0      NaN  \n",
       "11         observation    NaN       NaN      0.0  \n",
       "12         observation    NaN       NaN      2.0  \n",
       "13         observation    NaN       NaN      1.0  \n",
       "14        intervention    0.0   30000.0      NaN  \n",
       "15        intervention    0.0   10000.0      NaN  \n",
       "16        intervention    0.0   30000.0      NaN  \n",
       "17        intervention    0.0   10000.0      NaN  \n",
       "18        intervention    0.0  100000.0      NaN  \n",
       "19        intervention    0.0     100.0      NaN  \n",
       "20        intervention    0.0      10.0      NaN  \n",
       "21        intervention    0.0     300.0      NaN  \n",
       "22        intervention    0.0       5.0      NaN  \n",
       "23         observation    0.0      50.0      NaN  \n",
       "24         observation    0.0      50.0      NaN  \n",
       "25         observation    0.0     100.0      NaN  \n",
       "26         observation    0.0    1000.0      NaN  \n",
       "27         observation    0.0    1000.0      NaN  \n",
       "28         observation    0.0     100.0      NaN  \n",
       "29         observation    0.0     200.0      NaN  \n",
       "...                ...    ...       ...      ...  \n",
       "44         observation    0.0     500.0      NaN  \n",
       "45         observation    0.0   10000.0      NaN  \n",
       "46         observation    0.0     500.0      NaN  \n",
       "47         observation    0.0   10000.0      NaN  \n",
       "48         observation    0.0      25.0      NaN  \n",
       "49         observation    0.0     100.0      NaN  \n",
       "50         observation    0.0      25.0      NaN  \n",
       "51         observation    0.0     100.0      NaN  \n",
       "52         observation    0.0     100.0      NaN  \n",
       "53         observation    0.0     100.0      NaN  \n",
       "54         observation    0.0    1000.0      NaN  \n",
       "55         observation    0.0    1000.0      NaN  \n",
       "56         observation    0.0     100.0      NaN  \n",
       "57         observation    0.0    1000.0      NaN  \n",
       "58         observation    0.0    1000.0      NaN  \n",
       "59         observation    0.0     100.0      NaN  \n",
       "60         observation    0.0      14.0      NaN  \n",
       "61         observation    0.0      14.0      NaN  \n",
       "62         observation    0.0     200.0      NaN  \n",
       "63         observation    0.0     200.0      NaN  \n",
       "64         observation    0.0  100000.0      NaN  \n",
       "65         observation    0.0  100000.0      NaN  \n",
       "66         observation    0.0   10000.0      NaN  \n",
       "67         observation    0.0     100.0      NaN  \n",
       "68         observation    0.0       1.0      NaN  \n",
       "69         observation    0.0    1000.0      NaN  \n",
       "70         observation    0.0   10000.0      NaN  \n",
       "71         observation    0.0     500.0      NaN  \n",
       "72         observation    0.0     100.0      NaN  \n",
       "73         observation    0.0    1000.0      NaN  \n",
       "\n",
       "[74 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_state=42\n",
    "#test/train/val split\n",
    "train_ids,validate_ids,test_ids = test_train_val_split(print_ids=True,random_state=random_state);\n",
    "\n",
    "# Load Our Data Dict\n",
    "data_dict = icu_data_defs.data_dictionary('config/data_definitions.xlsx')\n",
    "display(data_dict.get_defs())\n",
    "\n",
    "#init ETL Manager => mimic_extract data\n",
    "hdf5_fname = 'data/mimic_extract.h5'\n",
    "mimic_etlM = mimic.MimicETLManager(hdf5_fname,'config/mimic_item_map.csv',data_dict)\n",
    "\n",
    "#init feature factory using data_dict, etl_manager\n",
    "factory = features.DataSetFactory(features=None,\n",
    "                                      resample_freq=None,\n",
    "                                      data_dict=data_dict,\n",
    "                                      ETL_manager=mimic_etlM,\n",
    "                                      hdf5_fname_target=None,\n",
    "                                      panel_id=12 #limit to simple data\n",
    "                                  )\n",
    "\n",
    "#create all features\n",
    "m_ureg = units.MedicalUreg()\n",
    "is_summable = lambda x: m_ureg.is_volume(str(x)) or m_ureg.is_mass(str(x))\n",
    "\n",
    "\"\"\"\n",
    "Data Specs\n",
    "\"\"\"\n",
    "qn_not_sum = {\n",
    "    column_names.VAR_TYPE : variable_type.QUANTITATIVE,\n",
    "    column_names.UNITS: lambda units: not is_summable(units)\n",
    "}\n",
    "\n",
    "weight = {\n",
    "    column_names.COMPONENT : data_dict.components.WEIGHT_BODY\n",
    "}\n",
    "\n",
    "intervention_summable = {\n",
    "    column_names.CLINICAL_SOURCE : clinical_source.INTERVENTION,\n",
    "    column_names.UNITS: is_summable\n",
    "}\n",
    "\n",
    "uop_summable = {\n",
    "    column_names.COMPONENT : data_dict.components.OUTPUT_URINE,\n",
    "    column_names.UNITS: is_summable\n",
    "}\n",
    "\n",
    "not_nominal = {\n",
    "    column_names.VAR_TYPE : [variable_type.QUANTITATIVE, variable_type.ORDINAL]\n",
    "}\n",
    "\n",
    "is_nominal = {\n",
    "    column_names.VAR_TYPE : variable_type.NOMINAL\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "Features\n",
    "\"\"\"\n",
    "# MEAN & LAST\n",
    "# For all non-summable quantities: \n",
    "# 1. ffill values\n",
    "# 2. Then resample and aggregate \n",
    "# 3. Then fill with mean of means\n",
    "f_qn_mean = features.Feature('MEAN','mean',\n",
    "                               data_specs=[qn_not_sum,weight],\n",
    "                               pre_processor=transformers.GroubyAndFFill(level=column_names.ID),\n",
    "                               fillna_method=transformers.fill_mean()\n",
    "                            )\n",
    "\n",
    "f_qn_most_recent = features.Feature('LAST','last',\n",
    "                                       data_specs=[qn_not_sum,weight],\n",
    "                                       pre_processor=transformers.GroubyAndFFill(level=column_names.ID),\n",
    "                                       fillna_method=transformers.fill_mean()\n",
    "                                   )\n",
    "# STD - fill NaN with 0\n",
    "f_qn_std = features.Feature('STD','std',\n",
    "                                data_specs=[not_nominal],\n",
    "                                fillna_method=transformers.fill_zero()\n",
    "                           )\n",
    "\n",
    "# SUM - for UOP volumes and intervention volumes/masses\n",
    "f_sum = features.Feature('SUM','sum',\n",
    "                             data_specs=[intervention_summable,uop_summable],\n",
    "                             fillna_method=transformers.fill_zero()\n",
    "                        )\n",
    "\n",
    "#only COUNT ordinal or quantitative data\n",
    "f_count = features.Feature('COUNT','count',\n",
    "                           data_specs=[not_nominal],\n",
    "                           fillna_method=transformers.fill_zero())\n",
    "\n",
    "#use SUM for nominal data (0's will be counted if we use count)\n",
    "f_count_nom = features.Feature('COUNT','sum',\n",
    "                             data_specs=[is_nominal],\n",
    "                             fillna_method=transformers.fill_zero()\n",
    "                        )\n",
    "\n",
    "\"\"\"\n",
    "Lactate Label\n",
    "\"\"\"\n",
    "# Label is lactate. just resampling; no preprocessing or filling\n",
    "label = features.Feature('LABEL','mean',{\n",
    "                                column_names.COMPONENT : data_dict.components.LACTATE,\n",
    "                                column_names.VAR_TYPE : variable_type.QUANTITATIVE\n",
    "                            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100014L, 100029L, 100039L, 100046L, 100052L] 9436\n"
     ]
    }
   ],
   "source": [
    "#start with a smaller data set\n",
    "reload(logger)\n",
    "\n",
    "train_subset = pd.Series(train_ids).sample(frac=0.2, random_state=random_state).sort_values().tolist()\n",
    "\n",
    "print train_subset[:5], len(train_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ETL_manager': <mimic.MimicETLManager at 0xe103630>,\n",
       " 'data_dict': <icu_data_defs.data_dictionary at 0x1067d940>,\n",
       " 'features': [<features.Feature at 0xe65ae48>,\n",
       "  <features.Feature at 0x10698f60>,\n",
       "  <features.Feature at 0xebd4518>,\n",
       "  <features.Feature at 0xebd44a8>,\n",
       "  <features.Feature at 0xebd4358>,\n",
       "  <features.Feature at 0xebd4630>,\n",
       "  <features.Feature at 0xebd4748>],\n",
       " 'force_preprocessing': True,\n",
       " 'hdf5_fname_target': 'data/combine_like.h5',\n",
       " 'panel_id': 12,\n",
       " 'pre_processors': Pipeline(steps=[('drop_small_columns', remove_small_columns(threshold=100)), ('drop_low_id_count', record_threshold(threshold=20)), ('combine_like_columns', combine_like_cols())]),\n",
       " 'pre_processors__combine_like_columns': combine_like_cols(),\n",
       " 'pre_processors__drop_low_id_count': record_threshold(threshold=20),\n",
       " 'pre_processors__drop_low_id_count__threshold': 20,\n",
       " 'pre_processors__drop_small_columns': remove_small_columns(threshold=100),\n",
       " 'pre_processors__drop_small_columns__threshold': 100,\n",
       " 'pre_processors__steps': [('drop_small_columns',\n",
       "   remove_small_columns(threshold=100)),\n",
       "  ('drop_low_id_count', record_threshold(threshold=20)),\n",
       "  ('combine_like_columns', combine_like_cols())],\n",
       " 'resample_freq': '2H',\n",
       " 'save_ETL_steps': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factory.hdf5_fname_target = 'data/combine_like.h5'\n",
    "factory.resample_freq='2H'\n",
    "factory.pre_processors = Pipeline([\n",
    "                                ('drop_small_columns',transformers.remove_small_columns(threshold=100)),\n",
    "                                ('drop_low_id_count',transformers.record_threshold(threshold=20)),\n",
    "                                ('combine_like_columns',transformers.combine_like_cols())\n",
    "                            ])\n",
    "factory.features = [f_qn_mean,f_qn_most_recent,f_qn_std,f_sum,f_count,f_count_nom,label]\n",
    "factory.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2017-08-03 11:32:22) FEATURIZE... #F=7, #ids=9436, fit->True\n",
      "(2017-08-03 11:32:22)>> PRE-PROCESSING & JOIN: #C=18, ['blood pressure diastolic', 'blood pressure mean', 'blood pressure systolic', 'glasgow coma scale eye opening', 'glasgow coma scale motor', 'glasgow coma scale verbal', 'heart rate', 'hemoglobin', 'lactate', 'lactated ringers', 'norepinephrine', 'normal saline', 'output urine', 'oxygen saturation pulse oximetry', 'respiratory rate', 'temperature body', 'vasopressin', 'weight body']\n",
      "(2017-08-03 11:32:24)>>>> blood pressure diastolic - 1/18\n",
      "(2017-08-03 11:32:24)>>>>>> READ DF...\n",
      "(2017-08-03 11:32:45)<<<<<< --- (21.0s)\n",
      "(2017-08-03 11:32:45)>>>>>> PREPROCESS...\n",
      "(2017-08-03 11:32:45)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:32:45)>>>>>> *fit* Filter columns (remove_small_columns) (985854, 42)\n",
      "(2017-08-03 11:32:45)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:32:45)>>>>>> *transform* Filter columns (remove_small_columns) (985854, 42)\n",
      "(2017-08-03 11:32:45)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:32:45)>>>>>> *fit* Filter columns (record_threshold) (985854, 12)\n",
      "(2017-08-03 11:32:45)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:32:45)>>>>>> *transform* Filter columns (record_threshold) (985854, 12)\n",
      "(2017-08-03 11:32:45)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:32:45)>>>>>> FIT Combine like columns (985854, 12)\n",
      "(2017-08-03 11:32:45)>>>>>>>> ('blood pressure diastolic', 'known', 'qn', 'mmHg')\n",
      "(2017-08-03 11:32:46)<<<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:32:46)>>>>>>>> ('blood pressure diastolic', 'unknown', 'qn', 'cc/min')\n",
      "(2017-08-03 11:32:46)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:32:46)<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:32:46)>>>>>> TRANSFORM Combine like columns (985854, 12)\n",
      "(2017-08-03 11:32:46)>>>>>>>> ('blood pressure diastolic', 'known', 'qn', 'mmHg')\n",
      "(2017-08-03 11:33:07)<<<<<<<< --- (21.0s)\n",
      "(2017-08-03 11:33:07)>>>>>>>> ('blood pressure diastolic', 'unknown', 'qn', 'cc/min')\n",
      "(2017-08-03 11:33:19)<<<<<<<< --- (12.0s)\n",
      "(2017-08-03 11:33:19)<<<<<< --- (33.0s)\n",
      "(2017-08-03 11:33:19)>>>>>> SAVE DF... (985709, 2) -> -1150879849/-1150879849/blood pressure diastolic\n",
      "(2017-08-03 11:33:22)<<<<<< --- (3.0s)\n",
      "(2017-08-03 11:33:22)<<<< --- (58.0s)\n",
      "(2017-08-03 11:33:22)>>>> blood pressure mean - 2/18\n",
      "(2017-08-03 11:33:22)>>>>>> READ DF...\n",
      "(2017-08-03 11:33:25)<<<<<< --- (3.0s)\n",
      "(2017-08-03 11:33:25)>>>>>> PREPROCESS...\n",
      "(2017-08-03 11:33:25)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:33:25)>>>>>> *fit* Filter columns (remove_small_columns) (414801, 3)\n",
      "(2017-08-03 11:33:25)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:33:25)>>>>>> *transform* Filter columns (remove_small_columns) (414801, 3)\n",
      "(2017-08-03 11:33:25)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:33:25)>>>>>> *fit* Filter columns (record_threshold) (414801, 3)\n",
      "(2017-08-03 11:33:25)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:33:25)>>>>>> *transform* Filter columns (record_threshold) (414801, 3)\n",
      "(2017-08-03 11:33:25)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:33:25)>>>>>> FIT Combine like columns (414801, 3)\n",
      "(2017-08-03 11:33:25)>>>>>>>> ('blood pressure mean', 'known', 'qn', 'mmHg')\n",
      "(2017-08-03 11:33:25)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:33:25)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:33:25)>>>>>> TRANSFORM Combine like columns (414801, 3)\n",
      "(2017-08-03 11:33:25)>>>>>>>> ('blood pressure mean', 'known', 'qn', 'mmHg')\n",
      "(2017-08-03 11:33:35)<<<<<<<< --- (10.0s)\n",
      "(2017-08-03 11:33:35)<<<<<< --- (10.0s)\n",
      "(2017-08-03 11:33:35)>>>>>> SAVE DF... (414654, 1) -> -1150879849/-1150879849/blood pressure mean\n",
      "(2017-08-03 11:33:36)<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:33:36)<<<< --- (14.0s)\n",
      "(2017-08-03 11:33:36)>>>> blood pressure systolic - 3/18\n",
      "(2017-08-03 11:33:36)>>>>>> READ DF...\n",
      "(2017-08-03 11:33:56)<<<<<< --- (20.0s)\n",
      "(2017-08-03 11:33:56)>>>>>> PREPROCESS...\n",
      "(2017-08-03 11:33:56)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:33:56)>>>>>> *fit* Filter columns (remove_small_columns) (985564, 40)\n",
      "(2017-08-03 11:33:56)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:33:56)>>>>>> *transform* Filter columns (remove_small_columns) (985564, 40)\n",
      "(2017-08-03 11:33:56)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:33:56)>>>>>> *fit* Filter columns (record_threshold) (985564, 13)\n",
      "(2017-08-03 11:33:57)<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:33:57)>>>>>> *transform* Filter columns (record_threshold) (985564, 13)\n",
      "(2017-08-03 11:33:57)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:33:57)>>>>>> FIT Combine like columns (985564, 13)\n",
      "(2017-08-03 11:33:57)>>>>>>>> ('blood pressure systolic', 'known', 'qn', 'mmHg')\n",
      "(2017-08-03 11:33:57)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:33:57)>>>>>>>> ('blood pressure systolic', 'unknown', 'qn', 'cc/min')\n",
      "(2017-08-03 11:33:57)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:33:57)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:33:57)>>>>>> TRANSFORM Combine like columns (985564, 13)\n",
      "(2017-08-03 11:33:57)>>>>>>>> ('blood pressure systolic', 'unknown', 'qn', 'cc/min')\n",
      "(2017-08-03 11:34:12)<<<<<<<< --- (15.0s)\n",
      "(2017-08-03 11:34:12)>>>>>>>> ('blood pressure systolic', 'known', 'qn', 'mmHg')\n",
      "(2017-08-03 11:34:29)<<<<<<<< --- (17.0s)\n",
      "(2017-08-03 11:34:29)<<<<<< --- (32.0s)\n",
      "(2017-08-03 11:34:29)>>>>>> SAVE DF... (985557, 2) -> -1150879849/-1150879849/blood pressure systolic\n",
      "(2017-08-03 11:34:32)<<<<<< --- (3.0s)\n",
      "(2017-08-03 11:34:32)<<<< --- (56.0s)\n",
      "(2017-08-03 11:34:32)>>>> glasgow coma scale eye opening - 4/18\n",
      "(2017-08-03 11:34:32)>>>>>> READ DF...\n",
      "(2017-08-03 11:34:33)<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:34:33)>>>>>> PREPROCESS...\n",
      "(2017-08-03 11:34:33)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:33)>>>>>> *fit* Filter columns (remove_small_columns) (153765, 1)\n",
      "(2017-08-03 11:34:33)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:33)>>>>>> *transform* Filter columns (remove_small_columns) (153765, 1)\n",
      "(2017-08-03 11:34:33)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:33)>>>>>> *fit* Filter columns (record_threshold) (153765, 1)\n",
      "(2017-08-03 11:34:33)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:33)>>>>>> *transform* Filter columns (record_threshold) (153765, 1)\n",
      "(2017-08-03 11:34:33)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:33)>>>>>> FIT Combine like columns (153765, 1)\n",
      "(2017-08-03 11:34:33)>>>>>>>> ('glasgow coma scale eye opening', 'known', 'ord', 'no_units')\n",
      "(2017-08-03 11:34:33)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:33)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:33)>>>>>> TRANSFORM Combine like columns (153765, 1)\n",
      "(2017-08-03 11:34:33)>>>>>>>> ('glasgow coma scale eye opening', 'known', 'ord', 'no_units')\n",
      "(2017-08-03 11:34:35)<<<<<<<< --- (2.0s)\n",
      "(2017-08-03 11:34:35)<<<<<< --- (2.0s)\n",
      "(2017-08-03 11:34:35)>>>>>> SAVE DF... (153765, 1) -> -1150879849/-1150879849/glasgow coma scale eye opening\n",
      "(2017-08-03 11:34:35)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:35)<<<< --- (3.0s)\n",
      "(2017-08-03 11:34:35)>>>> glasgow coma scale motor - 5/18\n",
      "(2017-08-03 11:34:35)>>>>>> READ DF...\n",
      "(2017-08-03 11:34:37)<<<<<< --- (2.0s)\n",
      "(2017-08-03 11:34:37)>>>>>> PREPROCESS...\n",
      "(2017-08-03 11:34:37)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:37)>>>>>> *fit* Filter columns (remove_small_columns) (153030, 1)\n",
      "(2017-08-03 11:34:37)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:37)>>>>>> *transform* Filter columns (remove_small_columns) (153030, 1)\n",
      "(2017-08-03 11:34:37)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:37)>>>>>> *fit* Filter columns (record_threshold) (153030, 1)\n",
      "(2017-08-03 11:34:37)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:37)>>>>>> *transform* Filter columns (record_threshold) (153030, 1)\n",
      "(2017-08-03 11:34:37)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:37)>>>>>> FIT Combine like columns (153030, 1)\n",
      "(2017-08-03 11:34:37)>>>>>>>> ('glasgow coma scale motor', 'known', 'ord', 'no_units')\n",
      "(2017-08-03 11:34:37)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:37)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:37)>>>>>> TRANSFORM Combine like columns (153030, 1)\n",
      "(2017-08-03 11:34:37)>>>>>>>> ('glasgow coma scale motor', 'known', 'ord', 'no_units')\n",
      "(2017-08-03 11:34:38)<<<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:34:38)<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:34:38)>>>>>> SAVE DF... (153030, 1) -> -1150879849/-1150879849/glasgow coma scale motor\n",
      "(2017-08-03 11:34:39)<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:34:39)<<<< --- (4.0s)\n",
      "(2017-08-03 11:34:39)>>>> glasgow coma scale verbal - 6/18\n",
      "(2017-08-03 11:34:39)>>>>>> READ DF...\n",
      "(2017-08-03 11:34:40)<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:34:40)>>>>>> PREPROCESS...\n",
      "(2017-08-03 11:34:40)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:40)>>>>>> *fit* Filter columns (remove_small_columns) (153421, 1)\n",
      "(2017-08-03 11:34:40)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:40)>>>>>> *transform* Filter columns (remove_small_columns) (153421, 1)\n",
      "(2017-08-03 11:34:40)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:40)>>>>>> *fit* Filter columns (record_threshold) (153421, 1)\n",
      "(2017-08-03 11:34:40)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:40)>>>>>> *transform* Filter columns (record_threshold) (153421, 1)\n",
      "(2017-08-03 11:34:40)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:40)>>>>>> FIT Combine like columns (153421, 1)\n",
      "(2017-08-03 11:34:40)>>>>>>>> ('glasgow coma scale verbal', 'known', 'ord', 'no_units')\n",
      "(2017-08-03 11:34:40)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:40)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:40)>>>>>> TRANSFORM Combine like columns (153421, 1)\n",
      "(2017-08-03 11:34:40)>>>>>>>> ('glasgow coma scale verbal', 'known', 'ord', 'no_units')\n",
      "(2017-08-03 11:34:42)<<<<<<<< --- (2.0s)\n",
      "(2017-08-03 11:34:42)<<<<<< --- (2.0s)\n",
      "(2017-08-03 11:34:42)>>>>>> SAVE DF... (153421, 1) -> -1150879849/-1150879849/glasgow coma scale verbal\n",
      "(2017-08-03 11:34:43)<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:34:43)<<<< --- (4.0s)\n",
      "(2017-08-03 11:34:43)>>>> heart rate - 7/18\n",
      "(2017-08-03 11:34:43)>>>>>> READ DF...\n",
      "(2017-08-03 11:34:54)<<<<<< --- (11.0s)\n",
      "(2017-08-03 11:34:54)>>>>>> PREPROCESS...\n",
      "(2017-08-03 11:34:54)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:54)>>>>>> *fit* Filter columns (remove_small_columns) (1324365, 6)\n",
      "(2017-08-03 11:34:54)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:54)>>>>>> *transform* Filter columns (remove_small_columns) (1324365, 6)\n",
      "(2017-08-03 11:34:54)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:54)>>>>>> *fit* Filter columns (record_threshold) (1324365, 3)\n",
      "(2017-08-03 11:34:54)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:54)>>>>>> *transform* Filter columns (record_threshold) (1324365, 3)\n",
      "(2017-08-03 11:34:54)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:34:54)>>>>>> FIT Combine like columns (1324365, 3)\n",
      "(2017-08-03 11:34:54)>>>>>>>> ('heart rate', 'known', 'qn', 'beats/min')\n",
      "(2017-08-03 11:34:55)<<<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:34:55)<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:34:55)>>>>>> TRANSFORM Combine like columns (1324365, 3)\n",
      "(2017-08-03 11:34:55)>>>>>>>> ('heart rate', 'known', 'qn', 'beats/min')\n",
      "(2017-08-03 11:35:20)<<<<<<<< --- (25.0s)\n",
      "(2017-08-03 11:35:20)<<<<<< --- (25.0s)\n",
      "(2017-08-03 11:35:21)>>>>>> SAVE DF... (1324351, 1) -> -1150879849/-1150879849/heart rate\n",
      "(2017-08-03 11:35:24)<<<<<< --- (3.0s)\n",
      "(2017-08-03 11:35:24)<<<< --- (41.0s)\n",
      "(2017-08-03 11:35:24)>>>> hemoglobin - 8/18\n",
      "(2017-08-03 11:35:24)>>>>>> READ DF...\n",
      "(2017-08-03 11:35:27)<<<<<< --- (3.0s)\n",
      "(2017-08-03 11:35:27)>>>>>> PREPROCESS...\n",
      "(2017-08-03 11:35:27)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:27)>>>>>> *fit* Filter columns (remove_small_columns) (108697, 44)\n",
      "(2017-08-03 11:35:27)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:27)>>>>>> *transform* Filter columns (remove_small_columns) (108697, 44)\n",
      "(2017-08-03 11:35:27)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:27)>>>>>> *fit* Filter columns (record_threshold) (108697, 8)\n",
      "(2017-08-03 11:35:27)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:27)>>>>>> *transform* Filter columns (record_threshold) (108697, 8)\n",
      "(2017-08-03 11:35:27)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:27)>>>>>> FIT Combine like columns (108697, 8)\n",
      "(2017-08-03 11:35:27)>>>>>>>> ('hemoglobin', 'known', 'qn', 'g/dL')\n",
      "(2017-08-03 11:35:27)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:27)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:27)>>>>>> TRANSFORM Combine like columns (108697, 8)\n",
      "(2017-08-03 11:35:27)>>>>>>>> ('hemoglobin', 'known', 'qn', 'g/dL')\n",
      "(2017-08-03 11:35:29)<<<<<<<< --- (2.0s)\n",
      "(2017-08-03 11:35:29)<<<<<< --- (2.0s)\n",
      "(2017-08-03 11:35:29)>>>>>> SAVE DF... (108683, 1) -> -1150879849/-1150879849/hemoglobin\n",
      "(2017-08-03 11:35:30)<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:35:30)<<<< --- (6.0s)\n",
      "(2017-08-03 11:35:30)>>>> lactate - 9/18\n",
      "(2017-08-03 11:35:30)>>>>>> READ DF...\n",
      "(2017-08-03 11:35:31)<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:35:31)>>>>>> PREPROCESS...\n",
      "(2017-08-03 11:35:31)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:31)>>>>>> *fit* Filter columns (remove_small_columns) (28278, 63)\n",
      "(2017-08-03 11:35:31)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:31)>>>>>> *transform* Filter columns (remove_small_columns) (28278, 63)\n",
      "(2017-08-03 11:35:31)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:31)>>>>>> *fit* Filter columns (record_threshold) (28278, 4)\n",
      "(2017-08-03 11:35:31)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:31)>>>>>> *transform* Filter columns (record_threshold) (28278, 4)\n",
      "(2017-08-03 11:35:31)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:31)>>>>>> FIT Combine like columns (28278, 4)\n",
      "(2017-08-03 11:35:31)>>>>>>>> ('lactate', 'known', 'qn', 'mmol/L')\n",
      "(2017-08-03 11:35:31)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:31)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:31)>>>>>> TRANSFORM Combine like columns (28278, 4)\n",
      "(2017-08-03 11:35:31)>>>>>>>> ('lactate', 'known', 'qn', 'mmol/L')\n",
      "(2017-08-03 11:35:32)<<<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:35:32)<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:35:32)>>>>>> SAVE DF... (28246, 1) -> -1150879849/-1150879849/lactate\n",
      "(2017-08-03 11:35:32)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:32)<<<< --- (2.0s)\n",
      "(2017-08-03 11:35:32)>>>> lactated ringers - 10/18\n",
      "(2017-08-03 11:35:32)>>>>>> READ DF...\n",
      "(2017-08-03 11:35:34)<<<<<< --- (2.0s)\n",
      "(2017-08-03 11:35:34)>>>>>> PREPROCESS...\n",
      "(2017-08-03 11:35:34)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:34)>>>>>> *fit* Filter columns (remove_small_columns) (40451, 20)\n",
      "(2017-08-03 11:35:34)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:34)>>>>>> *transform* Filter columns (remove_small_columns) (40451, 20)\n",
      "(2017-08-03 11:35:34)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:34)>>>>>> *fit* Filter columns (record_threshold) (40451, 5)\n",
      "(2017-08-03 11:35:34)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:34)>>>>>> *transform* Filter columns (record_threshold) (40451, 5)\n",
      "(2017-08-03 11:35:34)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:34)>>>>>> FIT Combine like columns (40451, 5)\n",
      "(2017-08-03 11:35:34)>>>>>>>> ('lactated ringers', 'known', 'qn', 'mL')\n",
      "(2017-08-03 11:35:34)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:34)>>>>>>>> ('lactated ringers', 'known', 'qn', 'mL/hr')\n",
      "(2017-08-03 11:35:34)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:34)>>>>>>>> ('lactated ringers', 'unknown', 'qn', 'no_units')\n",
      "(2017-08-03 11:35:34)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:34)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:34)>>>>>> TRANSFORM Combine like columns (40451, 5)\n",
      "(2017-08-03 11:35:34)>>>>>>>> ('lactated ringers', 'known', 'qn', 'mL/hr')\n",
      "(2017-08-03 11:35:34)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:34)>>>>>>>> ('lactated ringers', 'unknown', 'qn', 'no_units')\n",
      "(2017-08-03 11:35:34)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:34)>>>>>>>> ('lactated ringers', 'known', 'qn', 'mL')\n",
      "(2017-08-03 11:35:35)<<<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:35:35)<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:35:35)>>>>>> SAVE DF... (40284, 3) -> -1150879849/-1150879849/lactated ringers\n",
      "(2017-08-03 11:35:35)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:35)<<<< --- (3.0s)\n",
      "(2017-08-03 11:35:35)>>>> norepinephrine - 11/18\n",
      "(2017-08-03 11:35:35)>>>>>> READ DF...\n",
      "(2017-08-03 11:35:36)<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:35:36)>>>>>> PREPROCESS...\n",
      "(2017-08-03 11:35:36)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:36)>>>>>> *fit* Filter columns (remove_small_columns) (59948, 5)\n",
      "(2017-08-03 11:35:36)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:36)>>>>>> *transform* Filter columns (remove_small_columns) (59948, 5)\n",
      "(2017-08-03 11:35:36)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:36)>>>>>> *fit* Filter columns (record_threshold) (59948, 5)\n",
      "(2017-08-03 11:35:36)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:36)>>>>>> *transform* Filter columns (record_threshold) (59948, 5)\n",
      "(2017-08-03 11:35:36)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:36)>>>>>> FIT Combine like columns (59948, 5)\n",
      "(2017-08-03 11:35:36)>>>>>>>> ('norepinephrine', 'known', 'qn', 'mcg')\n",
      "(2017-08-03 11:35:36)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:36)>>>>>>>> ('norepinephrine', 'known', 'qn', 'mcg/kg/min')\n",
      "(2017-08-03 11:35:36)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:36)>>>>>>>> ('norepinephrine', 'known', 'qn', 'mcg/min')\n",
      "(2017-08-03 11:35:36)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:36)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:36)>>>>>> TRANSFORM Combine like columns (59948, 5)\n",
      "(2017-08-03 11:35:36)>>>>>>>> ('norepinephrine', 'known', 'qn', 'mcg/min')\n",
      "(2017-08-03 11:35:36)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:36)>>>>>>>> ('norepinephrine', 'known', 'qn', 'mcg/kg/min')\n",
      "(2017-08-03 11:35:37)<<<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:35:37)>>>>>>>> ('norepinephrine', 'known', 'qn', 'mcg')\n",
      "(2017-08-03 11:35:38)<<<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:35:38)<<<<<< --- (2.0s)\n",
      "(2017-08-03 11:35:38)>>>>>> SAVE DF... (59940, 3) -> -1150879849/-1150879849/norepinephrine\n",
      "(2017-08-03 11:35:39)<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:35:39)<<<< --- (4.0s)\n",
      "(2017-08-03 11:35:39)>>>> normal saline - 12/18\n",
      "(2017-08-03 11:35:39)>>>>>> READ DF...\n",
      "(2017-08-03 11:35:40)<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:35:40)>>>>>> PREPROCESS...\n",
      "(2017-08-03 11:35:40)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:40)>>>>>> *fit* Filter columns (remove_small_columns) (77035, 16)\n",
      "(2017-08-03 11:35:40)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:40)>>>>>> *transform* Filter columns (remove_small_columns) (77035, 16)\n",
      "(2017-08-03 11:35:40)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:40)>>>>>> *fit* Filter columns (record_threshold) (77035, 4)\n",
      "(2017-08-03 11:35:40)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:40)>>>>>> *transform* Filter columns (record_threshold) (77035, 4)\n",
      "(2017-08-03 11:35:40)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:40)>>>>>> FIT Combine like columns (77035, 4)\n",
      "(2017-08-03 11:35:40)>>>>>>>> ('normal saline', 'known', 'qn', 'mL')\n",
      "(2017-08-03 11:35:40)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:40)>>>>>>>> ('normal saline', 'known', 'qn', 'mL/hr')\n",
      "(2017-08-03 11:35:40)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:40)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:40)>>>>>> TRANSFORM Combine like columns (77035, 4)\n",
      "(2017-08-03 11:35:40)>>>>>>>> ('normal saline', 'known', 'qn', 'mL')\n",
      "(2017-08-03 11:35:42)<<<<<<<< --- (2.0s)\n",
      "(2017-08-03 11:35:42)>>>>>>>> ('normal saline', 'known', 'qn', 'mL/hr')\n",
      "(2017-08-03 11:35:42)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:35:42)<<<<<< --- (2.0s)\n",
      "(2017-08-03 11:35:42)>>>>>> SAVE DF... (76947, 2) -> -1150879849/-1150879849/normal saline\n",
      "(2017-08-03 11:35:43)<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:35:43)<<<< --- (4.0s)\n",
      "(2017-08-03 11:35:43)>>>> output urine - 13/18\n",
      "(2017-08-03 11:35:43)>>>>>> READ DF...\n",
      "(2017-08-03 11:36:12)<<<<<< --- (29.0s)\n",
      "(2017-08-03 11:36:12)>>>>>> PREPROCESS...\n",
      "(2017-08-03 11:36:12)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:36:12)>>>>>> *fit* Filter columns (remove_small_columns) (589962, 61)\n",
      "(2017-08-03 11:36:12)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:36:12)>>>>>> *transform* Filter columns (remove_small_columns) (589962, 61)\n",
      "(2017-08-03 11:36:12)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:36:12)>>>>>> *fit* Filter columns (record_threshold) (589962, 10)\n",
      "(2017-08-03 11:36:12)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:36:12)>>>>>> *transform* Filter columns (record_threshold) (589962, 10)\n",
      "(2017-08-03 11:36:12)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:36:12)>>>>>> FIT Combine like columns (589962, 9)\n",
      "(2017-08-03 11:36:12)>>>>>>>> ('output urine', 'known', 'qn', 'mL')\n",
      "(2017-08-03 11:36:12)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:36:12)>>>>>>>> ('output urine', 'unknown', 'nom', 'no_units')\n",
      "(2017-08-03 11:36:12)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:36:12)>>>>>>>> ('output urine', 'unknown', 'qn', 'no_units')\n",
      "(2017-08-03 11:36:12)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:36:12)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:36:12)>>>>>> TRANSFORM Combine like columns (589962, 9)\n",
      "(2017-08-03 11:36:12)>>>>>>>> ('output urine', 'unknown', 'qn', 'no_units')\n",
      "(2017-08-03 11:36:22)<<<<<<<< --- (10.0s)\n",
      "(2017-08-03 11:36:22)>>>>>>>> ('output urine', 'known', 'qn', 'mL')\n",
      "(2017-08-03 11:36:32)<<<<<<<< --- (10.0s)\n",
      "(2017-08-03 11:36:32)<<<<<< --- (20.0s)\n",
      "(2017-08-03 11:36:32)>>>>>> SAVE DF... (589962, 5) -> -1150879849/-1150879849/output urine\n",
      "(2017-08-03 11:36:34)<<<<<< --- (2.0s)\n",
      "(2017-08-03 11:36:34)<<<< --- (51.0s)\n",
      "(2017-08-03 11:36:34)>>>> oxygen saturation pulse oximetry - 14/18\n",
      "(2017-08-03 11:36:34)>>>>>> READ DF...\n",
      "(2017-08-03 11:36:40)<<<<<< --- (6.0s)\n",
      "(2017-08-03 11:36:40)>>>>>> PREPROCESS...\n",
      "(2017-08-03 11:36:40)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:36:40)>>>>>> *fit* Filter columns (remove_small_columns) (982829, 2)\n",
      "(2017-08-03 11:36:40)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:36:40)>>>>>> *transform* Filter columns (remove_small_columns) (982829, 2)\n",
      "(2017-08-03 11:36:40)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:36:40)>>>>>> *fit* Filter columns (record_threshold) (982829, 2)\n",
      "(2017-08-03 11:36:40)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:36:40)>>>>>> *transform* Filter columns (record_threshold) (982829, 2)\n",
      "(2017-08-03 11:36:40)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:36:40)>>>>>> FIT Combine like columns (982829, 2)\n",
      "(2017-08-03 11:36:40)>>>>>>>> ('oxygen saturation pulse oximetry', 'known', 'qn', 'percent')\n",
      "(2017-08-03 11:36:40)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:36:40)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:36:40)>>>>>> TRANSFORM Combine like columns (982829, 2)\n",
      "(2017-08-03 11:36:40)>>>>>>>> ('oxygen saturation pulse oximetry', 'known', 'qn', 'percent')\n",
      "(2017-08-03 11:37:02)<<<<<<<< --- (22.0s)\n",
      "(2017-08-03 11:37:02)<<<<<< --- (22.0s)\n",
      "(2017-08-03 11:37:02)>>>>>> SAVE DF... (982826, 1) -> -1150879849/-1150879849/oxygen saturation pulse oximetry\n",
      "(2017-08-03 11:37:06)<<<<<< --- (4.0s)\n",
      "(2017-08-03 11:37:06)<<<< --- (32.0s)\n",
      "(2017-08-03 11:37:06)>>>> respiratory rate - 15/18\n",
      "(2017-08-03 11:37:06)>>>>>> READ DF...\n",
      "(2017-08-03 11:37:15)<<<<<< --- (9.0s)\n",
      "(2017-08-03 11:37:15)>>>>>> PREPROCESS...\n",
      "(2017-08-03 11:37:15)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:15)>>>>>> *fit* Filter columns (remove_small_columns) (1298647, 6)\n",
      "(2017-08-03 11:37:15)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:15)>>>>>> *transform* Filter columns (remove_small_columns) (1298647, 6)\n",
      "(2017-08-03 11:37:15)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:15)>>>>>> *fit* Filter columns (record_threshold) (1298647, 3)\n",
      "(2017-08-03 11:37:15)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:15)>>>>>> *transform* Filter columns (record_threshold) (1298647, 3)\n",
      "(2017-08-03 11:37:15)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:15)>>>>>> FIT Combine like columns (1298647, 3)\n",
      "(2017-08-03 11:37:15)>>>>>>>> ('respiratory rate', 'known', 'qn', 'insp/min')\n",
      "(2017-08-03 11:37:15)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:15)>>>>>>>> ('respiratory rate', 'unknown', 'qn', 'Breath')\n",
      "(2017-08-03 11:37:15)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:15)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:15)>>>>>> TRANSFORM Combine like columns (1298647, 3)\n",
      "(2017-08-03 11:37:15)>>>>>>>> ('respiratory rate', 'known', 'qn', 'insp/min')\n",
      "(2017-08-03 11:37:39)<<<<<<<< --- (24.0s)\n",
      "(2017-08-03 11:37:39)>>>>>>>> ('respiratory rate', 'unknown', 'qn', 'Breath')\n",
      "(2017-08-03 11:37:44)<<<<<<<< --- (5.0s)\n",
      "(2017-08-03 11:37:44)<<<<<< --- (29.0s)\n",
      "(2017-08-03 11:37:44)>>>>>> SAVE DF... (1298633, 2) -> -1150879849/-1150879849/respiratory rate\n",
      "(2017-08-03 11:37:48)<<<<<< --- (4.0s)\n",
      "(2017-08-03 11:37:48)<<<< --- (42.0s)\n",
      "(2017-08-03 11:37:48)>>>> temperature body - 16/18\n",
      "(2017-08-03 11:37:48)>>>>>> READ DF...\n",
      "(2017-08-03 11:37:50)<<<<<< --- (2.0s)\n",
      "(2017-08-03 11:37:50)>>>>>> PREPROCESS...\n",
      "(2017-08-03 11:37:50)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:50)>>>>>> *fit* Filter columns (remove_small_columns) (274747, 4)\n",
      "(2017-08-03 11:37:50)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:50)>>>>>> *transform* Filter columns (remove_small_columns) (274747, 4)\n",
      "(2017-08-03 11:37:50)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:50)>>>>>> *fit* Filter columns (record_threshold) (274747, 4)\n",
      "(2017-08-03 11:37:50)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:50)>>>>>> *transform* Filter columns (record_threshold) (274747, 4)\n",
      "(2017-08-03 11:37:50)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:50)>>>>>> FIT Combine like columns (274747, 4)\n",
      "(2017-08-03 11:37:50)>>>>>>>> ('temperature body', 'known', 'qn', 'degF')\n",
      "(2017-08-03 11:37:50)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:50)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:50)>>>>>> TRANSFORM Combine like columns (274747, 4)\n",
      "(2017-08-03 11:37:50)>>>>>>>> ('temperature body', 'known', 'qn', 'degF')\n",
      "(2017-08-03 11:37:56)<<<<<<<< --- (6.0s)\n",
      "(2017-08-03 11:37:56)<<<<<< --- (6.0s)\n",
      "(2017-08-03 11:37:56)>>>>>> SAVE DF... (274712, 1) -> -1150879849/-1150879849/temperature body\n",
      "(2017-08-03 11:37:57)<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:37:57)<<<< --- (9.0s)\n",
      "(2017-08-03 11:37:57)>>>> vasopressin - 17/18\n",
      "(2017-08-03 11:37:57)>>>>>> READ DF...\n",
      "(2017-08-03 11:37:58)<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:37:58)>>>>>> PREPROCESS...\n",
      "(2017-08-03 11:37:58)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:58)>>>>>> *fit* Filter columns (remove_small_columns) (19048, 38)\n",
      "(2017-08-03 11:37:58)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:58)>>>>>> *transform* Filter columns (remove_small_columns) (19048, 38)\n",
      "(2017-08-03 11:37:58)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:58)>>>>>> *fit* Filter columns (record_threshold) (19048, 5)\n",
      "(2017-08-03 11:37:58)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:58)>>>>>> *transform* Filter columns (record_threshold) (19048, 5)\n",
      "(2017-08-03 11:37:58)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:58)>>>>>> FIT Combine like columns (19048, 4)\n",
      "(2017-08-03 11:37:58)>>>>>>>> ('vasopressin', 'known', 'qn', 'units')\n",
      "(2017-08-03 11:37:58)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:58)>>>>>>>> ('vasopressin', 'known', 'qn', 'units/min')\n",
      "(2017-08-03 11:37:58)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:58)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:58)>>>>>> TRANSFORM Combine like columns (19048, 4)\n",
      "(2017-08-03 11:37:58)>>>>>>>> ('vasopressin', 'known', 'qn', 'units/min')\n",
      "(2017-08-03 11:37:59)<<<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:37:59)>>>>>>>> ('vasopressin', 'known', 'qn', 'units')\n",
      "(2017-08-03 11:37:59)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:59)<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:37:59)>>>>>> SAVE DF... (18809, 2) -> -1150879849/-1150879849/vasopressin\n",
      "(2017-08-03 11:37:59)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:59)<<<< --- (2.0s)\n",
      "(2017-08-03 11:37:59)>>>> weight body - 18/18\n",
      "(2017-08-03 11:37:59)>>>>>> READ DF...\n",
      "(2017-08-03 11:37:59)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:59)>>>>>> PREPROCESS...\n",
      "(2017-08-03 11:37:59)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:59)>>>>>> *fit* Filter columns (remove_small_columns) (14779, 3)\n",
      "(2017-08-03 11:37:59)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:59)>>>>>> *transform* Filter columns (remove_small_columns) (14779, 3)\n",
      "(2017-08-03 11:37:59)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:59)>>>>>> *fit* Filter columns (record_threshold) (14779, 3)\n",
      "(2017-08-03 11:37:59)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:59)>>>>>> *transform* Filter columns (record_threshold) (14779, 3)\n",
      "(2017-08-03 11:37:59)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:59)>>>>>> FIT Combine like columns (14779, 3)\n",
      "(2017-08-03 11:37:59)>>>>>>>> ('weight body', 'known', 'qn', 'kg')\n",
      "(2017-08-03 11:37:59)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:59)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:37:59)>>>>>> TRANSFORM Combine like columns (14779, 3)\n",
      "(2017-08-03 11:37:59)>>>>>>>> ('weight body', 'known', 'qn', 'kg')\n",
      "(2017-08-03 11:38:00)<<<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:38:00)<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:38:00)>>>>>> SAVE DF... (14775, 1) -> -1150879849/-1150879849/weight body\n",
      "(2017-08-03 11:38:00)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:38:00)<<<< --- (1.0s)\n",
      "(2017-08-03 11:38:00)>>>> Smart join: n=9436, ['-1150879849/-1150879849/blood pressure diastolic', '-1150879849/-1150879849/blood pressure mean', '-1150879849/-1150879849/blood pressure systolic', '-1150879849/-1150879849/glasgow coma scale eye opening', '-1150879849/-1150879849/glasgow coma scale motor', '-1150879849/-1150879849/glasgow coma scale verbal', '-1150879849/-1150879849/heart rate', '-1150879849/-1150879849/hemoglobin', '-1150879849/-1150879849/lactate', '-1150879849/-1150879849/lactated ringers', '-1150879849/-1150879849/norepinephrine', '-1150879849/-1150879849/normal saline', '-1150879849/-1150879849/output urine', '-1150879849/-1150879849/oxygen saturation pulse oximetry', '-1150879849/-1150879849/respiratory rate', '-1150879849/-1150879849/temperature body', '-1150879849/-1150879849/vasopressin', '-1150879849/-1150879849/weight body']\n",
      "(2017-08-03 11:38:00)>>>>>> JOINING dataframes\n",
      "(2017-08-03 11:38:00)>>>>>>>> Slice & Join: 100014 --> 153092, n=5000\n",
      "(2017-08-03 11:38:00)>>>>>>>>>> -1150879849/-1150879849/blood pressure diastolic\n",
      "(2017-08-03 11:38:00)<<<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:38:00)>>>>>>>>>> -1150879849/-1150879849/blood pressure mean\n",
      "(2017-08-03 11:38:06)<<<<<<<<<< --- (6.0s)\n",
      "(2017-08-03 11:38:06)>>>>>>>>>> -1150879849/-1150879849/blood pressure systolic\n",
      "(2017-08-03 11:38:13)<<<<<<<<<< --- (7.0s)\n",
      "(2017-08-03 11:38:13)>>>>>>>>>> -1150879849/-1150879849/glasgow coma scale eye opening\n",
      "(2017-08-03 11:38:17)<<<<<<<<<< --- (4.0s)\n",
      "(2017-08-03 11:38:17)>>>>>>>>>> -1150879849/-1150879849/glasgow coma scale motor\n",
      "(2017-08-03 11:38:21)<<<<<<<<<< --- (4.0s)\n",
      "(2017-08-03 11:38:21)>>>>>>>>>> -1150879849/-1150879849/glasgow coma scale verbal\n",
      "(2017-08-03 11:38:26)<<<<<<<<<< --- (5.0s)\n",
      "(2017-08-03 11:38:26)>>>>>>>>>> -1150879849/-1150879849/heart rate\n",
      "(2017-08-03 11:38:34)<<<<<<<<<< --- (8.0s)\n",
      "(2017-08-03 11:38:34)>>>>>>>>>> -1150879849/-1150879849/hemoglobin\n",
      "(2017-08-03 11:38:39)<<<<<<<<<< --- (5.0s)\n",
      "(2017-08-03 11:38:39)>>>>>>>>>> -1150879849/-1150879849/lactate\n",
      "(2017-08-03 11:38:44)<<<<<<<<<< --- (5.0s)\n",
      "(2017-08-03 11:38:44)>>>>>>>>>> -1150879849/-1150879849/lactated ringers\n",
      "(2017-08-03 11:38:49)<<<<<<<<<< --- (5.0s)\n",
      "(2017-08-03 11:38:49)>>>>>>>>>> -1150879849/-1150879849/norepinephrine\n",
      "(2017-08-03 11:38:54)<<<<<<<<<< --- (5.0s)\n",
      "(2017-08-03 11:38:54)>>>>>>>>>> -1150879849/-1150879849/normal saline\n",
      "(2017-08-03 11:39:00)<<<<<<<<<< --- (6.0s)\n",
      "(2017-08-03 11:39:00)>>>>>>>>>> -1150879849/-1150879849/output urine\n",
      "(2017-08-03 11:39:08)<<<<<<<<<< --- (8.0s)\n",
      "(2017-08-03 11:39:08)>>>>>>>>>> -1150879849/-1150879849/oxygen saturation pulse oximetry\n",
      "(2017-08-03 11:39:17)<<<<<<<<<< --- (9.0s)\n",
      "(2017-08-03 11:39:17)>>>>>>>>>> -1150879849/-1150879849/respiratory rate\n",
      "(2017-08-03 11:39:27)<<<<<<<<<< --- (10.0s)\n",
      "(2017-08-03 11:39:27)>>>>>>>>>> -1150879849/-1150879849/temperature body\n",
      "(2017-08-03 11:39:34)<<<<<<<<<< --- (7.0s)\n",
      "(2017-08-03 11:39:34)>>>>>>>>>> -1150879849/-1150879849/vasopressin\n",
      "(2017-08-03 11:39:40)<<<<<<<<<< --- (6.0s)\n",
      "(2017-08-03 11:39:40)>>>>>>>>>> -1150879849/-1150879849/weight body\n",
      "(2017-08-03 11:39:46)<<<<<<<<<< --- (6.0s)\n",
      "(2017-08-03 11:39:46)<<<<<<<< --- (106.0s)\n",
      "(2017-08-03 11:39:46)>>>>>>>> Append slice\n",
      "(2017-08-03 11:39:50)<<<<<<<< --- (4.0s)\n",
      "(2017-08-03 11:39:50)>>>>>>>> Slice & Join: 153109 --> 199995, n=4436\n",
      "(2017-08-03 11:39:50)>>>>>>>>>> -1150879849/-1150879849/blood pressure diastolic\n",
      "(2017-08-03 11:39:50)<<<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:39:50)>>>>>>>>>> -1150879849/-1150879849/blood pressure mean\n",
      "(2017-08-03 11:39:54)<<<<<<<<<< --- (4.0s)\n",
      "(2017-08-03 11:39:54)>>>>>>>>>> -1150879849/-1150879849/blood pressure systolic\n",
      "(2017-08-03 11:40:00)<<<<<<<<<< --- (6.0s)\n",
      "(2017-08-03 11:40:00)>>>>>>>>>> -1150879849/-1150879849/glasgow coma scale eye opening\n",
      "(2017-08-03 11:40:04)<<<<<<<<<< --- (4.0s)\n",
      "(2017-08-03 11:40:04)>>>>>>>>>> -1150879849/-1150879849/glasgow coma scale motor\n",
      "(2017-08-03 11:40:08)<<<<<<<<<< --- (4.0s)\n",
      "(2017-08-03 11:40:08)>>>>>>>>>> -1150879849/-1150879849/glasgow coma scale verbal\n",
      "(2017-08-03 11:40:11)<<<<<<<<<< --- (3.0s)\n",
      "(2017-08-03 11:40:11)>>>>>>>>>> -1150879849/-1150879849/heart rate\n",
      "(2017-08-03 11:40:18)<<<<<<<<<< --- (7.0s)\n",
      "(2017-08-03 11:40:18)>>>>>>>>>> -1150879849/-1150879849/hemoglobin\n",
      "(2017-08-03 11:40:23)<<<<<<<<<< --- (5.0s)\n",
      "(2017-08-03 11:40:23)>>>>>>>>>> -1150879849/-1150879849/lactate\n",
      "(2017-08-03 11:40:27)<<<<<<<<<< --- (4.0s)\n",
      "(2017-08-03 11:40:27)>>>>>>>>>> -1150879849/-1150879849/lactated ringers\n",
      "(2017-08-03 11:40:32)<<<<<<<<<< --- (5.0s)\n",
      "(2017-08-03 11:40:32)>>>>>>>>>> -1150879849/-1150879849/norepinephrine\n",
      "(2017-08-03 11:40:36)<<<<<<<<<< --- (4.0s)\n",
      "(2017-08-03 11:40:36)>>>>>>>>>> -1150879849/-1150879849/normal saline\n",
      "(2017-08-03 11:40:41)<<<<<<<<<< --- (5.0s)\n",
      "(2017-08-03 11:40:41)>>>>>>>>>> -1150879849/-1150879849/output urine\n",
      "(2017-08-03 11:40:48)<<<<<<<<<< --- (7.0s)\n",
      "(2017-08-03 11:40:48)>>>>>>>>>> -1150879849/-1150879849/oxygen saturation pulse oximetry\n",
      "(2017-08-03 11:40:55)<<<<<<<<<< --- (7.0s)\n",
      "(2017-08-03 11:40:55)>>>>>>>>>> -1150879849/-1150879849/respiratory rate\n",
      "(2017-08-03 11:41:04)<<<<<<<<<< --- (9.0s)\n",
      "(2017-08-03 11:41:04)>>>>>>>>>> -1150879849/-1150879849/temperature body\n",
      "(2017-08-03 11:41:10)<<<<<<<<<< --- (6.0s)\n",
      "(2017-08-03 11:41:10)>>>>>>>>>> -1150879849/-1150879849/vasopressin\n",
      "(2017-08-03 11:41:15)<<<<<<<<<< --- (5.0s)\n",
      "(2017-08-03 11:41:15)>>>>>>>>>> -1150879849/-1150879849/weight body\n",
      "(2017-08-03 11:41:20)<<<<<<<<<< --- (5.0s)\n",
      "(2017-08-03 11:41:20)<<<<<<<< --- (90.0s)\n",
      "(2017-08-03 11:41:20)>>>>>>>> Append slice\n",
      "(2017-08-03 11:41:23)<<<<<<<< --- (3.0s)\n",
      "(2017-08-03 11:41:23)<<<<<< --- (203.0s)\n",
      "(2017-08-03 11:41:23)<<<< --- (203.0s)\n",
      "(2017-08-03 11:41:23)>>>> Read JOINED DF\n",
      "(2017-08-03 11:41:25)<<<< --- (2.0s)\n",
      "(2017-08-03 11:41:25)<< --- (543.0s)\n",
      "(2017-08-03 11:41:25)>> APPLY FEATURES, #F=7 to df=(1665320, 31)\n",
      "(2017-08-03 11:41:25)>>>> Featurizing: MEAN, [{'units': <function <lambda> at 0x000000000EA894A8>, 'variable_type': 'qn'}, {'component': 'weight body'}]\n",
      "(2017-08-03 11:41:25)>>>>>> *fit* Filter columns (DataSpecFilter) (1665320, 31)\n",
      "(2017-08-03 11:41:25)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:41:25)>>>>>> *transform* Filter columns (DataSpecFilter) (1665320, 31)\n",
      "(2017-08-03 11:41:32)<<<<<< --- (7.0s)\n",
      "(2017-08-03 11:41:32)>>>>>> *transform* RESAMPLE (1665320, 21), rule=2H, func=mean\n",
      "(2017-08-03 11:41:32)>>>>>>>> Resampling\n",
      "(2017-08-03 11:41:32)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:41:32)>>>>>>>> Aggregating\n",
      "(2017-08-03 11:42:05)<<<<<<<< --- (33.0s)\n",
      "(2017-08-03 11:42:05)<<<<<< --- (33.0s)\n",
      "(2017-08-03 11:42:05)>>>>>> Join\n",
      "(2017-08-03 11:42:05)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:42:05)<<<< --- (40.0s)\n",
      "(2017-08-03 11:42:05)>>>> Featurizing: LAST, [{'units': <function <lambda> at 0x000000000EA894A8>, 'variable_type': 'qn'}, {'component': 'weight body'}]\n",
      "(2017-08-03 11:42:05)>>>>>> *fit* Filter columns (DataSpecFilter) (1665320, 31)\n",
      "(2017-08-03 11:42:05)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:42:05)>>>>>> *transform* Filter columns (DataSpecFilter) (1665320, 31)\n",
      "(2017-08-03 11:42:12)<<<<<< --- (7.0s)\n",
      "(2017-08-03 11:42:12)>>>>>> *transform* RESAMPLE (1665320, 21), rule=2H, func=last\n",
      "(2017-08-03 11:42:12)>>>>>>>> Resampling\n",
      "(2017-08-03 11:42:12)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:42:12)>>>>>>>> Aggregating\n",
      "(2017-08-03 11:42:37)<<<<<<<< --- (25.0s)\n",
      "(2017-08-03 11:42:37)<<<<<< --- (25.0s)\n",
      "(2017-08-03 11:42:37)>>>>>> Join\n",
      "(2017-08-03 11:42:43)<<<<<< --- (6.0s)\n",
      "(2017-08-03 11:42:43)<<<< --- (38.0s)\n",
      "(2017-08-03 11:42:43)>>>> Featurizing: STD, [{'variable_type': ['qn', 'ord']}]\n",
      "(2017-08-03 11:42:43)>>>>>> *fit* Filter columns (DataSpecFilter) (1665320, 31)\n",
      "(2017-08-03 11:42:43)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:42:43)>>>>>> *transform* Filter columns (DataSpecFilter) (1665320, 31)\n",
      "(2017-08-03 11:42:43)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:42:43)>>>>>> *transform* RESAMPLE (1665320, 28), rule=2H, func=std\n",
      "(2017-08-03 11:42:43)>>>>>>>> Resampling\n",
      "(2017-08-03 11:42:44)<<<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:42:44)>>>>>>>> Aggregating\n",
      "(2017-08-03 11:43:18)<<<<<<<< --- (34.0s)\n",
      "(2017-08-03 11:43:18)<<<<<< --- (35.0s)\n",
      "(2017-08-03 11:43:18)>>>>>> Join\n",
      "(2017-08-03 11:43:22)<<<<<< --- (4.0s)\n",
      "(2017-08-03 11:43:22)<<<< --- (39.0s)\n",
      "(2017-08-03 11:43:22)>>>> Featurizing: SUM, [{'units': <function <lambda> at 0x000000000EA89A58>, 'clinical_source': 'intervention'}, {'units': <function <lambda> at 0x000000000EA89A58>, 'component': 'output urine'}]\n",
      "(2017-08-03 11:43:22)>>>>>> *fit* Filter columns (DataSpecFilter) (1665320, 31)\n",
      "(2017-08-03 11:43:22)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:43:22)>>>>>> *transform* Filter columns (DataSpecFilter) (1665320, 31)\n",
      "(2017-08-03 11:43:22)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:43:22)>>>>>> *transform* RESAMPLE (1665320, 4), rule=2H, func=sum\n",
      "(2017-08-03 11:43:22)>>>>>>>> Resampling\n",
      "(2017-08-03 11:43:22)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:43:22)>>>>>>>> Aggregating\n",
      "(2017-08-03 11:43:54)<<<<<<<< --- (32.0s)\n",
      "(2017-08-03 11:43:54)<<<<<< --- (32.0s)\n",
      "(2017-08-03 11:43:54)>>>>>> Join\n",
      "(2017-08-03 11:43:57)<<<<<< --- (3.0s)\n",
      "(2017-08-03 11:43:57)<<<< --- (35.0s)\n",
      "(2017-08-03 11:43:57)>>>> Featurizing: COUNT, [{'variable_type': ['qn', 'ord']}]\n",
      "(2017-08-03 11:43:57)>>>>>> *fit* Filter columns (DataSpecFilter) (1665320, 31)\n",
      "(2017-08-03 11:43:57)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:43:57)>>>>>> *transform* Filter columns (DataSpecFilter) (1665320, 31)\n",
      "(2017-08-03 11:43:57)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:43:57)>>>>>> *transform* RESAMPLE (1665320, 28), rule=2H, func=count\n",
      "(2017-08-03 11:43:58)>>>>>>>> Resampling\n",
      "(2017-08-03 11:43:58)<<<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:43:58)>>>>>>>> Aggregating\n",
      "(2017-08-03 11:44:22)<<<<<<<< --- (24.0s)\n",
      "(2017-08-03 11:44:22)<<<<<< --- (25.0s)\n",
      "(2017-08-03 11:44:22)>>>>>> Join\n",
      "(2017-08-03 11:44:25)<<<<<< --- (3.0s)\n",
      "(2017-08-03 11:44:25)<<<< --- (28.0s)\n",
      "(2017-08-03 11:44:25)>>>> Featurizing: COUNT, [{'variable_type': 'nom'}]\n",
      "(2017-08-03 11:44:25)>>>>>> *fit* Filter columns (DataSpecFilter) (1665320, 31)\n",
      "(2017-08-03 11:44:25)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:44:25)>>>>>> *transform* Filter columns (DataSpecFilter) (1665320, 31)\n",
      "(2017-08-03 11:44:25)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:44:25)>>>>>> *transform* RESAMPLE (1665320, 3), rule=2H, func=sum\n",
      "(2017-08-03 11:44:25)>>>>>>>> Resampling\n",
      "(2017-08-03 11:44:26)<<<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:44:26)>>>>>>>> Aggregating\n",
      "(2017-08-03 11:44:58)<<<<<<<< --- (32.0s)\n",
      "(2017-08-03 11:44:58)<<<<<< --- (33.0s)\n",
      "(2017-08-03 11:44:58)>>>>>> Join\n",
      "(2017-08-03 11:45:01)<<<<<< --- (3.0s)\n",
      "(2017-08-03 11:45:01)<<<< --- (36.0s)\n",
      "(2017-08-03 11:45:01)>>>> Featurizing: LABEL, {'variable_type': 'qn', 'component': 'lactate'}\n",
      "(2017-08-03 11:45:01)>>>>>> *fit* Filter columns (DataSpecFilter) (1665320, 31)\n",
      "(2017-08-03 11:45:01)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:45:01)>>>>>> *transform* Filter columns (DataSpecFilter) (1665320, 31)\n",
      "(2017-08-03 11:45:01)<<<<<< --- (0.0s)\n",
      "(2017-08-03 11:45:01)>>>>>> *transform* RESAMPLE (1665320, 1), rule=2H, func=mean\n",
      "(2017-08-03 11:45:01)>>>>>>>> Resampling\n",
      "(2017-08-03 11:45:02)<<<<<<<< --- (1.0s)\n",
      "(2017-08-03 11:45:02)>>>>>>>> Aggregating\n",
      "(2017-08-03 11:45:33)<<<<<<<< --- (31.0s)\n",
      "(2017-08-03 11:45:33)<<<<<< --- (32.0s)\n",
      "(2017-08-03 11:45:33)>>>>>> Join\n",
      "(2017-08-03 11:45:36)<<<<<< --- (3.0s)\n",
      "(2017-08-03 11:45:36)<<<< --- (35.0s)\n",
      "(2017-08-03 11:45:36)<< --- (251.0s)\n",
      "(2017-08-03 11:45:36) --- (794.0s)\n"
     ]
    }
   ],
   "source": [
    "df_train = factory.fit_transform(train_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_next = get_labels_next_lac(df_train.loc[:,'LABEL'])\n",
    "y_delta = get_labels_delta_lac(df_train.loc[:,'LABEL'])\n",
    "label_dict = {'NEXT_lactate' : y_next, 'DELTA_lactate':y_delta}\n",
    "\n",
    "df_features = df_train.drop('LABEL',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MEAN', 'blood pressure diastolic', 'known', 'qn', 'mmHg', 'all')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>MEAN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>blood pressure diastolic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>known</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>qn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mmHg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1052741.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>58.4419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.5781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>58.4419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>58.4419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58.4419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>228.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          MEAN\n",
       "      blood pressure diastolic\n",
       "                         known\n",
       "                            qn\n",
       "                          mmHg\n",
       "                           all\n",
       "count             1052741.0000\n",
       "mean                   58.4419\n",
       "std                    10.5781\n",
       "min                     0.0000\n",
       "25%                    58.4419\n",
       "50%                    58.4419\n",
       "75%                    58.4419\n",
       "max                   228.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Can only compare identically-labeled Series objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-c3367960f25f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_corr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mviz_per_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-32f17441b752>\u001b[0m in \u001b[0;36mviz_per_feature\u001b[1;34m(df_features, label_dict)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;31m#determine # of filled values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mmode_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m\"MODE:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mmode_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\genkinjz\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas\\core\\ops.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other, axis)\u001b[0m\n\u001b[0;32m    810\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indexed_same\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Can only compare identically-labeled Series objects'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m             return self._constructor(na_op(self.values, other.values),\n\u001b[0;32m    814\u001b[0m                                      index=self.index, name=name)\n",
      "\u001b[1;31mValueError\u001b[0m: Can only compare identically-labeled Series objects"
     ]
    }
   ],
   "source": [
    "df_corr = viz_per_feature(df_features,label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_corr"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
